RAG-LLM Metrics Evaluation Framework

A streamlined framework to evaluate RAG based LLM using ragas framework with automated metrics and customizable benchmarks.

Key Features
- Evaluate RAG pipelines with metrics like ContextPrecision, ContextRecall, Faitfulnes and another 4 
- Plug-and-play integration with OpenAI and ragas framework
- Auto-generate test datasets and reports
- Supports local and remote model evaluation
- Built-in pytest suite for easy automation

Quick Start

```bash
git clone https://github.com/mesandeepat/RAG-LLM-metrics-evaluation-framework.git
cd RAG-LLM-metrics-evaluation-framework
pip install -r requirements.txt

Note: Ensure you add your OPENAI_API_KEY and RAGAS_KEY

